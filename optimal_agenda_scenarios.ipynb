{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ChallengeXHEC23022024.xlsx\"\n",
    "dict_df_sheets = pd.read_excel(data_path, sheet_name=None)\n",
    "df_hist_jan = dict_df_sheets[\"JAN24\"].copy()\n",
    "df_clients = dict_df_sheets[\"clients\"].copy()\n",
    "df_inter = dict_df_sheets[\"intervenants\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data exploration preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hist_jan.rename(\n",
    "#     {\n",
    "#         \"ID Client\": \"id_client\",\n",
    "#         \"ID Intervenant\": \"id_inter\",\n",
    "#         \"Date\": \"date\",\n",
    "#         \"Heure de début\": \"start\",\n",
    "#         \"Heure de fin\": \"end\",\n",
    "#         \"Prestation\": \"obj\",\n",
    "#     },\n",
    "#     axis=1,\n",
    "#     inplace=True,\n",
    "# )\n",
    "\n",
    "# df_clients.rename(\n",
    "#     {\"ID Client\": \"id_client\", \"Latitude\": \"lat_client\", \"Longitude\": \"lon_client\"},\n",
    "#     axis=1,\n",
    "#     inplace=True,\n",
    "# )\n",
    "\n",
    "# df_inter.rename(\n",
    "#     {\n",
    "#         \"ID Intervenant\": \"id_inter\",\n",
    "#         \"Latitude\": \"lat_inter\",\n",
    "#         \"Longitude\": \"lon_inter\",\n",
    "#         \"Compétences\": \"skills\",\n",
    "#         \"Permis\": \"license\",\n",
    "#         \"Véhicule personnel\": \"car\",\n",
    "#         \"Dispo / Indispo\": \"free\",\n",
    "#     },\n",
    "#     axis=1,\n",
    "#     inplace=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hist_jan[\"date\"] = pd.to_datetime(df_hist_jan[\"date\"])\n",
    "# df_hist_jan[\"start\"] = pd.to_datetime(df_hist_jan[\"date\"])\n",
    "# df_hist_jan[\"date\"] = pd.to_datetime(df_hist_jan[\"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modeling with Google OR Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ortools.constraint_solver import routing_enums_pb2\n",
    "from ortools.constraint_solver import pywrapcp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.C.1. With initial locations, time windows, bike/car time travel, task execution time and skills with REAL DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_c_dist = pd.read_csv(\"client_client_distance.csv\")\n",
    "c_l_need = pd.read_csv(\"client_loc_need.csv\")\n",
    "c_n_dist = pd.read_csv(\"client_nurse_distance.csv\")\n",
    "\n",
    "list_clients_1 = c_c_dist[\"ID Client 1\"].unique()\n",
    "list_clients_2 = c_c_dist[\"ID Client 2\"].unique()\n",
    "full_client_list = list(set([*list_clients_1, *list_clients_2]))\n",
    "nb_full_client = len(full_client_list)\n",
    "\n",
    "c_l_need.drop(columns=[\"Unnamed: 0\", \"Latitude\", \"Longitude\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id_to_idx = {}\n",
    "client_idx_to_id = {}\n",
    "for k in range(len(full_client_list)):\n",
    "    client_id_to_idx[full_client_list[k]] = k\n",
    "    client_idx_to_id[k] = full_client_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_duration(str_duration):\n",
    "    if \"hour\" in str_duration:\n",
    "        list = str_duration.split()\n",
    "        nb_minutes = int(list[0]) * 60 + int(list[2])\n",
    "        return nb_minutes\n",
    "    else:\n",
    "        list = str_duration.split()\n",
    "        nb_minutes = int(list[0])\n",
    "        return nb_minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_client_time_matrix(\n",
    "    df, vehicle_type, client_id_to_idx=client_id_to_idx, out_value=4000\n",
    "):\n",
    "    list_clients_1 = df[\"ID Client 1\"].unique()\n",
    "    list_clients_2 = df[\"ID Client 2\"].unique()\n",
    "    full_list = list(set([*list_clients_1, *list_clients_2]))\n",
    "\n",
    "    matrix = [[0 for i in range(len(full_list))] for k in range(len(full_list))]\n",
    "    col_type = \"Duration_\" + vehicle_type\n",
    "    for client_1_id in full_list:\n",
    "        client_1_idx = client_id_to_idx[client_1_id]\n",
    "        for client_2_id in full_list:\n",
    "            client_2_idx = client_id_to_idx[client_2_id]\n",
    "            if client_1_id != client_2_id:\n",
    "                try:\n",
    "                    travel_time = convert_duration(\n",
    "                        df.loc[\n",
    "                            (df[\"ID Client 1\"] == client_1_id)\n",
    "                            & (df[\"ID Client 2\"] == client_2_id),\n",
    "                            col_type,\n",
    "                        ].values[0]\n",
    "                    )\n",
    "                    matrix[client_1_idx][client_2_idx] = travel_time\n",
    "                except IndexError:\n",
    "                    try:\n",
    "                        travel_time = convert_duration(\n",
    "                            df.loc[\n",
    "                                (df[\"ID Client 1\"] == client_2_id)\n",
    "                                & (df[\"ID Client 2\"] == client_1_id),\n",
    "                                col_type,\n",
    "                            ].values[0]\n",
    "                        )\n",
    "                        matrix[client_1_idx][client_2_idx] = travel_time\n",
    "                    except IndexError:\n",
    "                        matrix[client_1_idx][client_2_idx] = out_value\n",
    "\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_time_matrix_car = define_client_time_matrix(c_c_dist, vehicle_type=\"Car\")\n",
    "client_time_matrix_bike = define_client_time_matrix(c_c_dist, vehicle_type=\"Bike\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_inter_columns = c_n_dist.columns[2:]\n",
    "full_inter_list = list(set([int(x.split(sep=\"_\")[2]) for x in list_inter_columns]))\n",
    "\n",
    "inter_id_to_idx = {}\n",
    "inter_idx_to_id = {}\n",
    "for k in range(len(full_inter_list)):\n",
    "    inter_id_to_idx[full_inter_list[k]] = k\n",
    "    inter_idx_to_id[k] = full_inter_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_inter_time_matrix(\n",
    "    df,\n",
    "    full_client_list,\n",
    "    inter_id_to_idx=inter_id_to_idx,\n",
    "    client_id_to_idx=client_id_to_idx,\n",
    "    vehicle_type=\"Car\",\n",
    "    out_value=4000,\n",
    "):\n",
    "    list_inter_columns = df.columns[2:]\n",
    "    full_inter_list = list(set([int(x.split(sep=\"_\")[2]) for x in list_inter_columns]))\n",
    "\n",
    "    matrix = [\n",
    "        [0 for i in range(len(full_client_list))] for k in range(len(full_inter_list))\n",
    "    ]\n",
    "\n",
    "    for inter_id in full_inter_list:\n",
    "        vehicle_str = \"_Driving\" if vehicle_type == \"Car\" else \"_Bicycling\"\n",
    "        col_name = \"Duration_Intervenant_\" + str(inter_id) + vehicle_str\n",
    "        inter_idx = inter_id_to_idx[inter_id]\n",
    "\n",
    "        for client_id in full_client_list:\n",
    "            client_idx = client_id_to_idx[client_id]\n",
    "            try:\n",
    "                travel_time = convert_duration(\n",
    "                    df.loc[df[\"ID Client\"] == client_id, col_name].values[0]\n",
    "                )\n",
    "                matrix[inter_idx][client_idx] = travel_time\n",
    "            except IndexError:\n",
    "                matrix[inter_idx][client_idx] = out_value\n",
    "\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_time_matrix_car = define_inter_time_matrix(\n",
    "    c_n_dist, full_client_list, vehicle_type=\"Car\"\n",
    ")\n",
    "inter_time_matrix_bike = define_inter_time_matrix(\n",
    "    c_n_dist, full_client_list, vehicle_type=\"Bike\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_time_matrix(client_time_matrix, inter_time_matrix, out_value=4000):\n",
    "    nb_client = client_time_matrix.shape[0]\n",
    "    nb_inter = inter_time_matrix.shape[0]\n",
    "\n",
    "    matrix = [\n",
    "        [out_value for i in range(nb_client + nb_inter)]\n",
    "        for k in range(nb_client + nb_inter)\n",
    "    ]\n",
    "\n",
    "    for i in range(nb_client):\n",
    "        for j in range(nb_client):\n",
    "            matrix[i][j] = client_time_matrix[i][j]\n",
    "\n",
    "    for i in range(nb_inter):\n",
    "        for j in range(nb_client):\n",
    "            matrix[i + nb_client][j] = inter_time_matrix[i][j]\n",
    "            matrix[j][i + nb_client] = matrix[i + nb_client][j]\n",
    "\n",
    "    return np.array(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_time_matrix_car = create_full_time_matrix(\n",
    "    client_time_matrix_car, inter_time_matrix_car\n",
    ")\n",
    "full_time_matrix_bike = create_full_time_matrix(\n",
    "    client_time_matrix_bike, inter_time_matrix_bike\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/95/2w4zxm7j571dt7gznpftznw80000gn/T/ipykernel_42525/3667956813.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  c_l_test.drop(columns=[\"Date\"], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID Client</th>\n",
       "      <th>Prestation</th>\n",
       "      <th>Durée</th>\n",
       "      <th>tranche_horaire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>559475456</td>\n",
       "      <td>REPAS</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>559277088</td>\n",
       "      <td>TOILETTE</td>\n",
       "      <td>45.0</td>\n",
       "      <td>[7, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87852633</td>\n",
       "      <td>TOILETTE</td>\n",
       "      <td>45.0</td>\n",
       "      <td>[7, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243033408</td>\n",
       "      <td>TOILETTE</td>\n",
       "      <td>30.0</td>\n",
       "      <td>[7, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>814940942</td>\n",
       "      <td>TOILETTE</td>\n",
       "      <td>95.0</td>\n",
       "      <td>[7, 11]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Client Prestation  Durée tranche_horaire\n",
       "0  559475456      REPAS   30.0          [7, 9]\n",
       "1  559277088   TOILETTE   45.0         [7, 11]\n",
       "2   87852633   TOILETTE   45.0         [7, 11]\n",
       "3  243033408   TOILETTE   30.0         [7, 11]\n",
       "4  814940942   TOILETTE   95.0         [7, 11]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_skills = c_l_need[\"Prestation\"].unique()\n",
    "\n",
    "condition = c_l_need[\"Date\"] == \"2024-01-01\"\n",
    "c_l_test = c_l_need[condition]\n",
    "c_l_test.drop(columns=[\"Date\"], inplace=True)\n",
    "# c_l_test = c_l_test[:70]\n",
    "c_l_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Data preparation for scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"ChallengeXHEC23022024.xlsx\"\n",
    "dict_df_sheets = pd.read_excel(data_path, sheet_name=None)\n",
    "df_hist_jan = dict_df_sheets[\"JAN24\"].copy()\n",
    "df_clients = dict_df_sheets[\"clients\"].copy()\n",
    "df_inter = dict_df_sheets[\"intervenants\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_jan_dates = [\"2024-01-\" + (\"0\" if k < 10 else \"\") + str(k) for k in range(1, 32)]\n",
    "df_inter_columns = [*df_inter.columns[:7], *list_jan_dates]\n",
    "df_inter.columns = df_inter_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_locations = [\n",
    "    (df_clients[\"Latitude\"][k], df_clients[\"Longitude\"][k])\n",
    "    for k in range(len(df_clients))\n",
    "]\n",
    "\n",
    "inter_locations = [\n",
    "    (df_inter[\"Latitude\"][k], df_inter[\"Longitude\"][k]) for k in range(len(df_inter))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id_to_location = {}\n",
    "for k in range(len(df_clients)):\n",
    "    client_id_to_location[int(df_clients[\"ID Client\"][k])] = client_locations[k]\n",
    "\n",
    "inter_id_to_location = {}\n",
    "for k in range(len(df_inter)):\n",
    "    inter_id_to_location[int(df_inter[\"ID Intervenant\"][k])] = inter_locations[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_og_available(date, df_inter):\n",
    "    condition = df_inter[date] == 1\n",
    "    list_available_og = list(df_inter[condition][\"ID Intervenant\"])\n",
    "    return list_available_og"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Travel time estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>car</th>\n",
       "      <th>bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.732218</td>\n",
       "      <td>1.363744</td>\n",
       "      <td>48.705077</td>\n",
       "      <td>1.333307</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.732218</td>\n",
       "      <td>1.363744</td>\n",
       "      <td>48.638658</td>\n",
       "      <td>1.517034</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.732218</td>\n",
       "      <td>1.363744</td>\n",
       "      <td>48.787278</td>\n",
       "      <td>1.441202</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.732218</td>\n",
       "      <td>1.363744</td>\n",
       "      <td>48.768307</td>\n",
       "      <td>1.403410</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.732218</td>\n",
       "      <td>1.363744</td>\n",
       "      <td>48.725093</td>\n",
       "      <td>1.427367</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9586</th>\n",
       "      <td>48.758099</td>\n",
       "      <td>1.210611</td>\n",
       "      <td>48.689927</td>\n",
       "      <td>1.351054</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9587</th>\n",
       "      <td>48.758099</td>\n",
       "      <td>1.210611</td>\n",
       "      <td>48.763226</td>\n",
       "      <td>1.241120</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9588</th>\n",
       "      <td>48.729206</td>\n",
       "      <td>1.371985</td>\n",
       "      <td>48.689927</td>\n",
       "      <td>1.351054</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9589</th>\n",
       "      <td>48.729206</td>\n",
       "      <td>1.371985</td>\n",
       "      <td>48.763226</td>\n",
       "      <td>1.241120</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>48.689927</td>\n",
       "      <td>1.351054</td>\n",
       "      <td>48.763226</td>\n",
       "      <td>1.241120</td>\n",
       "      <td>4000</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9591 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x_1       y_1        x_2       y_2   car  bike\n",
       "0     48.732218  1.363744  48.705077  1.333307     7    14\n",
       "1     48.732218  1.363744  48.638658  1.517034    24    63\n",
       "2     48.732218  1.363744  48.787278  1.441202    16    38\n",
       "3     48.732218  1.363744  48.768307  1.403410    10    24\n",
       "4     48.732218  1.363744  48.725093  1.427367    11    25\n",
       "...         ...       ...        ...       ...   ...   ...\n",
       "9586  48.758099  1.210611  48.689927  1.351054  4000  4000\n",
       "9587  48.758099  1.210611  48.763226  1.241120  4000  4000\n",
       "9588  48.729206  1.371985  48.689927  1.351054  4000  4000\n",
       "9589  48.729206  1.371985  48.763226  1.241120  4000  4000\n",
       "9590  48.689927  1.351054  48.763226  1.241120  4000  4000\n",
       "\n",
       "[9591 rows x 6 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clients = len(full_client_list)\n",
    "nb_inter = len(full_inter_list)\n",
    "nb_loc = len(full_time_matrix_car)\n",
    "\n",
    "travel_time_data = []\n",
    "\n",
    "for i in range(nb_loc - 1):\n",
    "    for j in range(i + 1, nb_loc):\n",
    "        row = []\n",
    "        if i < nb_clients:\n",
    "            client_id_1 = client_idx_to_id[i]\n",
    "            row.append(client_id_to_location[client_id_1][0])\n",
    "            row.append(client_id_to_location[client_id_1][1])\n",
    "\n",
    "            if j < nb_clients:\n",
    "                client_id_2 = client_idx_to_id[j]\n",
    "                row.append(client_id_to_location[client_id_2][0])\n",
    "                row.append(client_id_to_location[client_id_2][1])\n",
    "            else:\n",
    "                inter_id_2 = inter_idx_to_id[j - nb_clients]\n",
    "                row.append(inter_id_to_location[inter_id_2][0])\n",
    "                row.append(inter_id_to_location[inter_id_2][1])\n",
    "\n",
    "        else:\n",
    "            inter_id = inter_idx_to_id[i - nb_clients]\n",
    "            row.append(inter_id_to_location[inter_id][0])\n",
    "            row.append(inter_id_to_location[inter_id][1])\n",
    "\n",
    "            if j < nb_clients:\n",
    "                client_id_2 = client_idx_to_id[j]\n",
    "                row.append(client_id_to_location[client_id_2][0])\n",
    "                row.append(client_id_to_location[client_id_2][1])\n",
    "            else:\n",
    "                inter_id_2 = inter_idx_to_id[j - nb_clients]\n",
    "                row.append(inter_id_to_location[inter_id_2][0])\n",
    "                row.append(inter_id_to_location[inter_id_2][1])\n",
    "\n",
    "        row.append(full_time_matrix_car[i][j])\n",
    "        row.append(full_time_matrix_bike[i][j])\n",
    "\n",
    "        travel_time_data.append(row)\n",
    "\n",
    "travel_time_df = pd.DataFrame(\n",
    "    travel_time_data, columns=[\"x_1\", \"y_1\", \"x_2\", \"y_2\", \"car\", \"bike\"]\n",
    ")\n",
    "travel_time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = travel_time_df[\"car\"] != 4000\n",
    "car_travel_time_df = travel_time_df[condition].copy()\n",
    "X_car = np.array(car_travel_time_df.drop(columns=[\"car\", \"bike\"]))\n",
    "y_car = np.array(car_travel_time_df[\"car\"])\n",
    "\n",
    "car_time_travel_estimator = RandomForestRegressor()\n",
    "car_time_travel_estimator.fit(X_car, y_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = travel_time_df[\"bike\"] != 4000\n",
    "bike_travel_time_df = travel_time_df[condition].copy()\n",
    "X_bike = np.array(bike_travel_time_df.drop(columns=[\"car\", \"bike\"]))\n",
    "y_bike = np.array(bike_travel_time_df[\"bike\"])\n",
    "\n",
    "bike_time_travel_estimator = RandomForestRegressor()\n",
    "bike_time_travel_estimator.fit(X_bike, y_bike)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Add new client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create artificially a new client the following way:\n",
    "\n",
    "- Get a random ('Prestation', 'Durée', 'Tranche horaire') from an existing client;\n",
    "- Get a random location\n",
    "\n",
    "From the random location, infere the travel time to each other node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clients_in_time_matrix(\n",
    "    client_synthetic_locations,\n",
    "    time_matrix_car,\n",
    "    time_matrix_bike,\n",
    "    df_og_need,\n",
    "    list_available_inter,\n",
    "):\n",
    "    nb_og_clients = len(df_og_need)\n",
    "    len_new_matrix = (\n",
    "        nb_og_clients + len(client_synthetic_locations) + len(list_available_inter)\n",
    "    )\n",
    "    new_car_matrix = [\n",
    "        [4000 for k in range(len_new_matrix)] for k in range(len_new_matrix)\n",
    "    ]\n",
    "    new_bike_matrix = [\n",
    "        [4000 for k in range(len_new_matrix)] for k in range(len_new_matrix)\n",
    "    ]\n",
    "\n",
    "    nb_synth_clients = len(client_synthetic_locations)\n",
    "\n",
    "    for i in range(len_new_matrix - 1):\n",
    "        for j in range(i + 1, len_new_matrix):\n",
    "            if i < nb_og_clients:\n",
    "                if j < nb_og_clients:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j]\n",
    "                elif nb_og_clients <= j < nb_og_clients + nb_synth_clients:\n",
    "                    # client_id_1 = client_idx_to_id[i]\n",
    "                    client_id_1 = df_og_need[\"ID Client\"][i]\n",
    "                    client_loc_1 = client_id_to_location[client_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                else:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j - nb_synth_clients]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j - nb_synth_clients]\n",
    "            elif nb_og_clients <= i < nb_og_clients + nb_synth_clients:\n",
    "                if j < nb_og_clients + nb_synth_clients:\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                else:\n",
    "                    # inter_id_1 = inter_idx_to_id[j - nb_og_clients - nb_synth_clients]\n",
    "                    # print(i)\n",
    "                    # print(j)\n",
    "                    # print(j - nb_og_clients - nb_synth_clients)\n",
    "                    # print(\"\\n\")\n",
    "                    inter_id_1 = list_available_inter[\n",
    "                        j - nb_og_clients - nb_synth_clients\n",
    "                    ]\n",
    "                    inter_loc_1 = inter_id_to_location[inter_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "            else:\n",
    "                new_car_matrix[i][j] = time_matrix_car[i - nb_synth_clients][\n",
    "                    j - nb_synth_clients\n",
    "                ]\n",
    "                new_bike_matrix[i][j] = time_matrix_bike[i - nb_synth_clients][\n",
    "                    j - nb_synth_clients\n",
    "                ]\n",
    "\n",
    "            new_car_matrix[j][i] = new_car_matrix[i][j]\n",
    "            new_bike_matrix[j][i] = new_bike_matrix[i][j]\n",
    "\n",
    "    for i in range(len_new_matrix):\n",
    "        new_car_matrix[i][i] = 0\n",
    "        new_bike_matrix[i][i] = 0\n",
    "\n",
    "    return np.array(new_car_matrix), np.array(new_bike_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Add new inter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create artificially a new inter the following way:\n",
    "\n",
    "- Get a random ('Skills', 'Disponibility', 'Car') from existing inter (can be different ones);\n",
    "- Get a random location\n",
    "\n",
    "From the random location, infere the travel time to each other node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clients_and_inter_in_time_matrix(\n",
    "    client_synthetic_locations,\n",
    "    inter_synthetic_locations,\n",
    "    time_matrix_car,\n",
    "    time_matrix_bike,\n",
    "    df_og_need,\n",
    "    list_available_inter,\n",
    "):\n",
    "    nb_og_clients = len(df_og_need)\n",
    "    nb_og_inter = len(list_available_inter)\n",
    "    len_new_matrix = (\n",
    "        len(client_synthetic_locations)\n",
    "        + len(inter_synthetic_locations)\n",
    "        + len(time_matrix_car)\n",
    "    )\n",
    "    new_car_matrix = [\n",
    "        [4000 for k in range(len_new_matrix)] for k in range(len_new_matrix)\n",
    "    ]\n",
    "    new_bike_matrix = [\n",
    "        [4000 for k in range(len_new_matrix)] for k in range(len_new_matrix)\n",
    "    ]\n",
    "\n",
    "    nb_synth_clients = len(client_synthetic_locations)\n",
    "    nb_synth_inter = len(inter_synthetic_locations)\n",
    "\n",
    "    for i in range(len_new_matrix - 1):\n",
    "        for j in range(i + 1, len_new_matrix):\n",
    "            if i < nb_og_clients:\n",
    "                if j < nb_og_clients:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j]\n",
    "                elif nb_og_clients <= j < nb_og_clients + nb_synth_clients:\n",
    "                    client_id_1 = df_og_need[\"ID Client\"][i]\n",
    "                    client_loc_1 = client_id_to_location[client_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                elif (\n",
    "                    nb_og_clients + nb_synth_clients\n",
    "                    <= j\n",
    "                    < nb_og_clients + nb_synth_clients + nb_og_inter\n",
    "                ):\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j - nb_synth_clients]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j - nb_synth_clients]\n",
    "                else:\n",
    "                    client_id_1 = df_og_need[\"ID Client\"][i]\n",
    "                    client_loc_1 = client_id_to_location[client_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "            elif nb_og_clients <= i < nb_og_clients + nb_synth_clients:\n",
    "                if j < nb_og_clients + nb_synth_clients:\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[j - nb_og_clients][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                elif (\n",
    "                    nb_og_clients + nb_synth_clients\n",
    "                    <= j\n",
    "                    < nb_og_clients + nb_synth_clients + nb_og_inter\n",
    "                ):\n",
    "                    # inter_id_1 = inter_idx_to_id[j - nb_og_clients - nb_synth_clients]\n",
    "                    inter_id_1 = list_available_inter[\n",
    "                        j - nb_og_clients - nb_synth_clients\n",
    "                    ]\n",
    "                    inter_loc_1 = inter_id_to_location[inter_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                else:\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_synthetic_locations[i - nb_og_clients][0],\n",
    "                                    client_synthetic_locations[i - nb_og_clients][1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "            elif (\n",
    "                nb_og_clients + nb_synth_clients\n",
    "                <= i\n",
    "                < nb_og_clients + nb_synth_clients + nb_og_inter\n",
    "            ):\n",
    "                if j < nb_og_clients + nb_synth_clients + nb_og_inter:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i - nb_synth_clients][\n",
    "                        j - nb_synth_clients\n",
    "                    ]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i - nb_synth_clients][\n",
    "                        j - nb_synth_clients\n",
    "                    ]\n",
    "                else:\n",
    "                    # inter_id_1 = inter_idx_to_id[i - nb_synth_clients - nb_og_clients]\n",
    "                    inter_id_1 = list_available_inter[\n",
    "                        i - nb_og_clients - nb_synth_clients\n",
    "                    ]\n",
    "                    inter_loc_1 = inter_id_to_location[inter_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j\n",
    "                                        - nb_og_clients\n",
    "                                        - nb_synth_clients\n",
    "                                        - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "            else:\n",
    "                new_car_matrix[i][j] = round(\n",
    "                    car_time_travel_estimator.predict(\n",
    "                        [\n",
    "                            [\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                            ]\n",
    "                        ]\n",
    "                    )[0]\n",
    "                )\n",
    "                new_bike_matrix[i][j] = round(\n",
    "                    bike_time_travel_estimator.predict(\n",
    "                        [\n",
    "                            [\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_synth_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                            ]\n",
    "                        ]\n",
    "                    )[0]\n",
    "                )\n",
    "\n",
    "            new_car_matrix[j][i] = new_car_matrix[i][j]\n",
    "            new_bike_matrix[j][i] = new_bike_matrix[i][j]\n",
    "\n",
    "    for i in range(len_new_matrix):\n",
    "        new_car_matrix[i][i] = 0\n",
    "        new_bike_matrix[i][i] = 0\n",
    "\n",
    "    return np.array(new_car_matrix), np.array(new_bike_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_inter_in_time_matrix(\n",
    "    inter_synthetic_locations,\n",
    "    time_matrix_car,\n",
    "    time_matrix_bike,\n",
    "    df_og_need,\n",
    "    list_available_inter,\n",
    "):\n",
    "    nb_og_clients = len(df_og_need)\n",
    "    nb_og_inter = len(list_available_inter)\n",
    "    len_new_matrix = +len(inter_synthetic_locations) + len(time_matrix_car)\n",
    "    new_car_matrix = [\n",
    "        [4000 for k in range(len_new_matrix)] for k in range(len_new_matrix)\n",
    "    ]\n",
    "    new_bike_matrix = [\n",
    "        [4000 for k in range(len_new_matrix)] for k in range(len_new_matrix)\n",
    "    ]\n",
    "\n",
    "    for i in range(len_new_matrix - 1):\n",
    "        for j in range(i + 1, len_new_matrix):\n",
    "            if i < nb_og_clients:\n",
    "                if j < nb_og_clients:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j]\n",
    "                elif nb_og_clients <= j < nb_og_clients + nb_og_inter:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j]\n",
    "                else:\n",
    "                    # client_id_1 = client_idx_to_id[i]\n",
    "                    client_id_1 = df_og_need[\"ID Client\"][i]\n",
    "                    client_loc_1 = client_id_to_location[client_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    client_loc_1[0],\n",
    "                                    client_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "            elif nb_og_clients <= i < nb_og_clients + nb_og_inter:\n",
    "                if j < nb_og_clients + nb_og_inter:\n",
    "                    new_car_matrix[i][j] = time_matrix_car[i][j]\n",
    "                    new_bike_matrix[i][j] = time_matrix_bike[i][j]\n",
    "                else:\n",
    "                    # inter_id_1 = inter_idx_to_id[i - nb_og_clients]\n",
    "                    inter_id_1 = list_available_inter[i - nb_og_clients]\n",
    "                    inter_loc_1 = inter_id_to_location[inter_id_1]\n",
    "                    new_car_matrix[i][j] = round(\n",
    "                        car_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "                    new_bike_matrix[i][j] = round(\n",
    "                        bike_time_travel_estimator.predict(\n",
    "                            [\n",
    "                                [\n",
    "                                    inter_loc_1[0],\n",
    "                                    inter_loc_1[1],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][0],\n",
    "                                    inter_synthetic_locations[\n",
    "                                        j - nb_og_clients - nb_og_inter\n",
    "                                    ][1],\n",
    "                                ]\n",
    "                            ]\n",
    "                        )[0]\n",
    "                    )\n",
    "            else:\n",
    "                new_car_matrix[i][j] = round(\n",
    "                    car_time_travel_estimator.predict(\n",
    "                        [\n",
    "                            [\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                            ]\n",
    "                        ]\n",
    "                    )[0]\n",
    "                )\n",
    "                new_bike_matrix[i][j] = round(\n",
    "                    bike_time_travel_estimator.predict(\n",
    "                        [\n",
    "                            [\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    i - nb_og_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_og_inter\n",
    "                                ][0],\n",
    "                                inter_synthetic_locations[\n",
    "                                    j - nb_og_clients - nb_og_inter\n",
    "                                ][1],\n",
    "                            ]\n",
    "                        ]\n",
    "                    )[0]\n",
    "                )\n",
    "\n",
    "            new_car_matrix[j][i] = new_car_matrix[i][j]\n",
    "            new_bike_matrix[j][i] = new_bike_matrix[i][j]\n",
    "\n",
    "    for i in range(len_new_matrix):\n",
    "        new_car_matrix[i][i] = 0\n",
    "        new_bike_matrix[i][i] = 0\n",
    "\n",
    "    return np.array(new_car_matrix), np.array(new_bike_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Add actors refined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_loc(nb_synth_loc, list_og_locations):\n",
    "    og_x_coords, og_y_coords = zip(*list_og_locations)\n",
    "\n",
    "    # Calculate mean and standard deviation for x and y\n",
    "    og_mean_x, og_std_x = np.mean(og_x_coords), np.std(og_x_coords)\n",
    "    og_mean_y, og_std_y = np.mean(og_y_coords), np.std(og_y_coords)\n",
    "\n",
    "    # Generate synthetic locations\n",
    "    list_synth_locations = [\n",
    "        (\n",
    "            np.random.normal(og_mean_x, og_std_x),\n",
    "            np.random.normal(og_mean_y, og_std_y),\n",
    "        )\n",
    "        for _ in range(nb_synth_loc)\n",
    "    ]\n",
    "\n",
    "    return list_synth_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_actors(\n",
    "    df_og_needs,\n",
    "    df_og_inter,\n",
    "    list_available_inter,\n",
    "    time_matrix_car,\n",
    "    time_matrix_bike,\n",
    "    nb_synth_clients=0,\n",
    "    nb_synth_inter=0,\n",
    "    client_locations=client_locations,\n",
    "    inter_locations=inter_locations,\n",
    "    inter_synth_constraints=False,\n",
    "    date=None,\n",
    "):\n",
    "    if nb_synth_inter == 0:\n",
    "        list_synth_client_loc = sample_random_loc(nb_synth_clients, client_locations)\n",
    "        new_car_time_matrix, new_bike_time_matrix = add_clients_in_time_matrix(\n",
    "            list_synth_client_loc,\n",
    "            time_matrix_car,\n",
    "            time_matrix_bike,\n",
    "            df_og_needs,\n",
    "            list_available_inter,\n",
    "        )\n",
    "\n",
    "        synth_client_needs_df = df_og_needs[\n",
    "            [\"Prestation\", \"Durée\", \"tranche_horaire\"]\n",
    "        ].sample(n=nb_synth_clients, replace=True)\n",
    "        synth_client_needs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        synth_available_inter_df = pd.DataFrame()\n",
    "\n",
    "    elif nb_synth_clients == 0:\n",
    "        synth_client_needs_df = pd.DataFrame()\n",
    "\n",
    "        synth_inter_df = df_og_inter.sample(n=nb_synth_inter, replace=True)\n",
    "        synth_inter_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        list_synth_inter_loc = sample_random_loc(nb_synth_inter, inter_locations)\n",
    "        synth_inter_df[\"Latitude\"] = [x[0] for x in list_synth_inter_loc]\n",
    "        synth_inter_df[\"Longitude\"] = [x[1] for x in list_synth_inter_loc]\n",
    "\n",
    "        if inter_synth_constraints:\n",
    "            condition = synth_inter_df[date] == 1\n",
    "            synth_available_inter_df = synth_inter_df[condition].copy()\n",
    "            nb_synth_inter = len(synth_available_inter_df)\n",
    "            list_synth_available_inter_loc = [\n",
    "                (\n",
    "                    synth_available_inter_df[\"Latitude\"][k],\n",
    "                    synth_available_inter_df[\"Longitude\"][k],\n",
    "                )\n",
    "                for k in range(len(synth_available_inter_df))\n",
    "            ]\n",
    "        else:\n",
    "            synth_available_inter_df = synth_inter_df\n",
    "            list_synth_available_inter_loc = list_synth_inter_loc\n",
    "\n",
    "        new_car_time_matrix, new_bike_time_matrix = add_inter_in_time_matrix(\n",
    "            list_synth_available_inter_loc,\n",
    "            time_matrix_car,\n",
    "            time_matrix_bike,\n",
    "            df_og_needs,\n",
    "            list_available_inter,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        list_synth_client_loc = sample_random_loc(nb_synth_clients, client_locations)\n",
    "\n",
    "        synth_client_needs_df = df_og_needs[\n",
    "            [\"Prestation\", \"Durée\", \"tranche_horaire\"]\n",
    "        ].sample(n=nb_synth_clients, replace=True)\n",
    "        synth_client_needs_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        synth_inter_df = df_og_inter.sample(n=nb_synth_inter, replace=True)\n",
    "        synth_inter_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        list_synth_inter_loc = sample_random_loc(nb_synth_inter, inter_locations)\n",
    "        synth_inter_df[\"Latitude\"] = [x[0] for x in list_synth_inter_loc]\n",
    "        synth_inter_df[\"Longitude\"] = [x[1] for x in list_synth_inter_loc]\n",
    "\n",
    "        if inter_synth_constraints:\n",
    "            condition = synth_inter_df[date] == 1\n",
    "            synth_available_inter_df = synth_inter_df[condition].copy()\n",
    "            nb_synth_inter = len(synth_available_inter_df)\n",
    "            list_synth_available_inter_loc = [\n",
    "                (\n",
    "                    synth_available_inter_df[\"Latitude\"][k],\n",
    "                    synth_available_inter_df[\"Longitude\"][k],\n",
    "                )\n",
    "                for k in range(len(synth_available_inter_df))\n",
    "            ]\n",
    "        else:\n",
    "            synth_available_inter_df = synth_inter_df\n",
    "            list_synth_available_inter_loc = list_synth_inter_loc\n",
    "\n",
    "        new_car_time_matrix, new_bike_time_matrix = (\n",
    "            add_clients_and_inter_in_time_matrix(\n",
    "                list_synth_client_loc,\n",
    "                list_synth_available_inter_loc,\n",
    "                time_matrix_car,\n",
    "                time_matrix_bike,\n",
    "                df_og_needs,\n",
    "                list_available_inter,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return (\n",
    "        new_car_time_matrix,\n",
    "        new_bike_time_matrix,\n",
    "        synth_client_needs_df,\n",
    "        synth_available_inter_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_real_data_model_with_synth(\n",
    "    df_og_need,\n",
    "    full_time_matrix_car,\n",
    "    full_time_matrix_bike,\n",
    "    list_available_inter,\n",
    "    nb_synth_clients=0,\n",
    "    nb_synth_inter=0,\n",
    "    client_id_to_idx=client_id_to_idx,\n",
    "    inter_id_to_idx=inter_id_to_idx,\n",
    "    nb_full_client=nb_full_client,\n",
    "    list_skills=list_skills,\n",
    "    df_inter=df_inter,\n",
    "):\n",
    "    nb_needs = len(df_og_need)\n",
    "    nb_inter = len(list_available_inter)\n",
    "    data = {}\n",
    "\n",
    "    # Initialization\n",
    "    data[\"og_time_matrix_car\"] = [\n",
    "        [4000 for i in range(nb_needs + nb_inter)] for k in range(nb_needs + nb_inter)\n",
    "    ]\n",
    "    data[\"og_time_matrix_bike\"] = [\n",
    "        [4000 for i in range(nb_needs + nb_inter)] for k in range(nb_needs + nb_inter)\n",
    "    ]\n",
    "    data[\"service_times\"] = [\n",
    "        0 for i in range(nb_needs + nb_inter + nb_synth_clients + nb_synth_inter)\n",
    "    ]\n",
    "    data[\"time_windows\"] = [\n",
    "        (0, 1440)\n",
    "        for i in range(nb_needs + nb_inter + nb_synth_clients + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    data[\"num_vehicles\"] = nb_inter + nb_synth_inter\n",
    "    data[\"is_car\"] = [\n",
    "        1 for i in range(nb_inter + nb_synth_inter)\n",
    "    ]  # For the moment every inter has a car\n",
    "    data[\"starts\"] = [\n",
    "        nb_needs + nb_synth_clients + i for i in range(nb_inter + nb_synth_inter)\n",
    "    ]\n",
    "    data[\"ends\"] = [\n",
    "        nb_needs + nb_synth_clients + i for i in range(nb_inter + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    data[\"vehicle_skills\"] = [\n",
    "        list_skills for i in range(nb_inter + nb_synth_inter)\n",
    "    ]  # For the moment every inter has all skills possible\n",
    "    data[\"node_requirements\"] = [\n",
    "        None for i in range(nb_needs + nb_inter + nb_synth_clients + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    # Create original time matrix\n",
    "    for i in range(nb_needs):\n",
    "        need_id_client = df_og_need[\"ID Client\"][i]\n",
    "        need_idx_client = client_id_to_idx[need_id_client]\n",
    "\n",
    "        for j in range(nb_needs):\n",
    "            other_id_client = df_og_need[\"ID Client\"][j]\n",
    "            other_idx_client = client_id_to_idx[other_id_client]\n",
    "\n",
    "            travel_time_car = full_time_matrix_car[need_idx_client, other_idx_client]\n",
    "            travel_time_bike = full_time_matrix_bike[need_idx_client, other_idx_client]\n",
    "            data[\"og_time_matrix_car\"][i][j] = travel_time_car\n",
    "            data[\"og_time_matrix_bike\"][i][j] = travel_time_bike\n",
    "\n",
    "        for j in range(nb_inter):\n",
    "            id_inter = list_available_inter[j]\n",
    "            idx_inter = inter_id_to_idx[id_inter]\n",
    "\n",
    "            travel_time_car = full_time_matrix_car[need_idx_client][\n",
    "                nb_full_client + idx_inter\n",
    "            ]\n",
    "            travel_time_bike = full_time_matrix_bike[need_idx_client][\n",
    "                nb_full_client + idx_inter\n",
    "            ]\n",
    "\n",
    "            data[\"og_time_matrix_car\"][i][nb_needs + j] = travel_time_car\n",
    "            data[\"og_time_matrix_car\"][nb_needs + j][i] = data[\"og_time_matrix_car\"][i][\n",
    "                nb_needs + j\n",
    "            ]\n",
    "            data[\"og_time_matrix_bike\"][i][nb_needs + j] = travel_time_bike\n",
    "            data[\"og_time_matrix_bike\"][nb_needs + j][i] = data[\"og_time_matrix_bike\"][\n",
    "                i\n",
    "            ][nb_needs + j]\n",
    "    for i in range(nb_needs + nb_inter):\n",
    "        data[\"og_time_matrix_car\"][i][i] = 0\n",
    "        data[\"og_time_matrix_bike\"][i][i] = 0\n",
    "\n",
    "    # Create new time matrix from orginial adding synthetic travel times\n",
    "    (\n",
    "        data[\"time_matrix_car\"],\n",
    "        data[\"time_matrix_bike\"],\n",
    "        synth_client_needs_df,\n",
    "        synth_inter_df,\n",
    "    ) = add_actors(\n",
    "        df_og_need,\n",
    "        df_inter,\n",
    "        list_available_inter,\n",
    "        data[\"og_time_matrix_car\"],\n",
    "        data[\"og_time_matrix_bike\"],\n",
    "        nb_synth_clients,\n",
    "        nb_synth_inter,\n",
    "        client_locations,\n",
    "        inter_locations,\n",
    "        inter_synth_constraints=int,\n",
    "    )\n",
    "\n",
    "    for i in range(nb_needs + nb_synth_clients):\n",
    "        if i < nb_needs:\n",
    "            service_time = int(df_og_need[\"Durée\"][i])\n",
    "            data[\"service_times\"][i] = service_time\n",
    "\n",
    "            time_window_temp = (\n",
    "                df_og_need[\"tranche_horaire\"][i]\n",
    "                .replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .split()\n",
    "            )\n",
    "            time_window_start = int(float(time_window_temp[0]) * 60)\n",
    "            time_window_end = int(float(time_window_temp[1]) * 60)\n",
    "            data[\"time_windows\"][i] = (time_window_start, time_window_end)\n",
    "\n",
    "            skills_required = df_og_need[\"Prestation\"][i]\n",
    "            data[\"node_requirements\"][i] = skills_required\n",
    "        else:\n",
    "            service_time = int(synth_client_needs_df[\"Durée\"][i - nb_needs])\n",
    "            data[\"service_times\"][i] = service_time\n",
    "\n",
    "            time_window_temp = (\n",
    "                synth_client_needs_df[\"tranche_horaire\"][i - nb_needs]\n",
    "                .replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .split()\n",
    "            )\n",
    "            time_window_start = int(float(time_window_temp[0]) * 60)\n",
    "            time_window_end = int(float(time_window_temp[1]) * 60)\n",
    "            data[\"time_windows\"][i] = (time_window_start, time_window_end)\n",
    "\n",
    "            skills_required = synth_client_needs_df[\"Prestation\"][i - nb_needs]\n",
    "            data[\"node_requirements\"][i] = skills_required\n",
    "\n",
    "    data[\"time_windows_with_service\"] = [\n",
    "        (\n",
    "            data[\"time_windows\"][i][0] + data[\"service_times\"][i],\n",
    "            data[\"time_windows\"][i][1] + data[\"service_times\"][i],\n",
    "        )\n",
    "        for i in range(len(data[\"service_times\"]))\n",
    "    ]\n",
    "\n",
    "    data[\"workload_per_node\"] = [1 for i in range(nb_needs + nb_synth_clients)].append(\n",
    "        [0 for k in range(nb_inter + nb_synth_inter)]\n",
    "    )  # Useless for now but could be used to differ workload from each node\n",
    "    data[\"workload_capacity\"] = [5 for i in range(nb_inter + nb_synth_inter)]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. Refined printing result function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eq_co2_car(travel_time):\n",
    "    # 10km = 1.9kg CO2\n",
    "    speed = 0.5  # km/min\n",
    "    return 1.9 * travel_time * speed / 10\n",
    "\n",
    "\n",
    "def eq_co2_elec_bike(travel_time):\n",
    "    # 10km = 20g CO2\n",
    "    speed = 1 / 3  # km/min\n",
    "    return 0.02 * travel_time * speed / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_detailed_solution_real_data(\n",
    "    data, manager, routing, solution, list_available_inter, verbose=0\n",
    "):\n",
    "    \"\"\"Prints detailed solution on console, including service and wait times.\"\"\"\n",
    "    # print(f\"Objective: {solution.ObjectiveValue()}\")\n",
    "    time_dimension = routing.GetDimensionOrDie(\"Time\")\n",
    "\n",
    "    nb_cars_used = 0\n",
    "    nb_bikes_used = 0\n",
    "    nb_inter_used = 0\n",
    "\n",
    "    nb_break_inf = 0\n",
    "    nb_break_sup = 0\n",
    "    nb_visits = 0\n",
    "\n",
    "    avg_length_day = 0\n",
    "    list_length_day = []\n",
    "\n",
    "    overall_total_car_commuting_time = 0\n",
    "    overall_total_bike_commuting_time = 0\n",
    "    overall_total_commuting_time = 0  # Initialize overall commuting time\n",
    "\n",
    "    # Display dropped nodes.\n",
    "    dropped_nodes = \"Dropped nodes:\"\n",
    "    count_dropped_nodes = 0\n",
    "    for node in range(routing.Size()):\n",
    "        if routing.IsStart(node) or routing.IsEnd(node):\n",
    "            continue\n",
    "        if solution.Value(routing.NextVar(node)) == node:\n",
    "            dropped_nodes += f\" {manager.IndexToNode(node)};\"\n",
    "            count_dropped_nodes += 1\n",
    "    print(f\"{dropped_nodes} (Total: {count_dropped_nodes})\")\n",
    "\n",
    "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
    "        index = routing.Start(vehicle_id)\n",
    "        vehicle_skills = str(data[\"vehicle_skills\"][vehicle_id])\n",
    "        try:\n",
    "            inter_id = list_available_inter[vehicle_id]\n",
    "        except IndexError:\n",
    "            inter_id = \"*synthetic*\"\n",
    "        vehicle_type_str = \"Car\" if data[\"is_car\"][vehicle_id] else \"Bike\"\n",
    "        if verbose == 1:\n",
    "            print(\n",
    "                f\"Route for vehicle {inter_id} (Type: {vehicle_type_str}; Skills: {vehicle_skills}):\"\n",
    "            )\n",
    "\n",
    "        vehicle_commuting_time = 0  # Initialize commuting time for the current vehicle\n",
    "        nb_steps = 0\n",
    "        start_day = 0\n",
    "        end_day = 0\n",
    "        nb_break_inf_veh = 0\n",
    "        nb_break_sup_veh = 0\n",
    "\n",
    "        # print(f\"Route for vehicle {inter_id}:\")\n",
    "        while not routing.IsEnd(index):\n",
    "            time_var = time_dimension.CumulVar(index)\n",
    "            next_index = solution.Value(routing.NextVar(index))\n",
    "            next_node = manager.IndexToNode(next_index)\n",
    "\n",
    "            if nb_steps == 1:\n",
    "                if data[\"is_car\"][vehicle_id]:\n",
    "                    nb_cars_used += 1\n",
    "                else:\n",
    "                    nb_bikes_used += 1\n",
    "                nb_inter_used += 1\n",
    "\n",
    "            service_time = data[\"service_times\"][manager.IndexToNode(index)]\n",
    "            skills_required = data[\"node_requirements\"][manager.IndexToNode(index)]\n",
    "            # Arrival time at current location\n",
    "            arrival_time = solution.Min(time_var) - service_time\n",
    "\n",
    "            # End of service time = arrival time + service time at current location\n",
    "            end_of_service_time = solution.Min(time_var)\n",
    "\n",
    "            # Initialization\n",
    "            departure_time = end_of_service_time\n",
    "\n",
    "            if data[\"is_car\"][vehicle_id]:\n",
    "                next_travel_time = data[\"time_matrix_car\"][manager.IndexToNode(index)][\n",
    "                    next_node\n",
    "                ]\n",
    "            else:\n",
    "                next_travel_time = data[\"time_matrix_bike\"][manager.IndexToNode(index)][\n",
    "                    next_node\n",
    "                ]\n",
    "            vehicle_commuting_time += next_travel_time\n",
    "            if data[\"is_car\"][vehicle_id]:\n",
    "                overall_total_car_commuting_time += next_travel_time\n",
    "            else:\n",
    "                overall_total_bike_commuting_time += next_travel_time\n",
    "            overall_total_commuting_time += next_travel_time\n",
    "\n",
    "            if next_index != routing.End(vehicle_id):\n",
    "                next_end_of_service_time = solution.Min(\n",
    "                    time_dimension.CumulVar(next_index)\n",
    "                )\n",
    "                next_service_time = data[\"service_times\"][next_node]\n",
    "                next_arrival_time = next_end_of_service_time - next_service_time\n",
    "                departure_time = next_arrival_time - next_travel_time\n",
    "\n",
    "            break_time = departure_time - end_of_service_time\n",
    "\n",
    "            if nb_steps > 0:\n",
    "                if break_time > 30:\n",
    "                    nb_break_sup += 1\n",
    "                    nb_break_sup_veh += 1\n",
    "                    nb_visits += 1\n",
    "                else:\n",
    "                    nb_visits += 1\n",
    "                    if next_index != routing.End(vehicle_id):\n",
    "                        nb_break_inf += 1\n",
    "                        nb_break_inf_veh += 1\n",
    "\n",
    "            if nb_steps == 0:\n",
    "                start_day = departure_time\n",
    "\n",
    "            nb_steps += 1\n",
    "\n",
    "            if next_index == routing.End(vehicle_id):\n",
    "                break_time = 0\n",
    "                departure_time = end_of_service_time\n",
    "\n",
    "            arrival_time_str = (\n",
    "                str(arrival_time // 60)\n",
    "                + \"h\"\n",
    "                + (\n",
    "                    str(arrival_time % 60)\n",
    "                    if arrival_time % 60 >= 10\n",
    "                    else \"0\" + str(arrival_time % 60)\n",
    "                )\n",
    "            )\n",
    "            end_of_service_time_str = (\n",
    "                str(end_of_service_time // 60)\n",
    "                + \"h\"\n",
    "                + (\n",
    "                    str(end_of_service_time % 60)\n",
    "                    if end_of_service_time % 60 >= 10\n",
    "                    else \"0\" + str(end_of_service_time % 60)\n",
    "                )\n",
    "            )\n",
    "            break_time_str = (\n",
    "                str(break_time // 60)\n",
    "                + \"h\"\n",
    "                + (\n",
    "                    str(break_time % 60)\n",
    "                    if break_time % 60 >= 10\n",
    "                    else \"0\" + str(break_time % 60)\n",
    "                )\n",
    "            )\n",
    "            departure_time_str = (\n",
    "                str(departure_time // 60)\n",
    "                + \"h\"\n",
    "                + (\n",
    "                    str(departure_time % 60)\n",
    "                    if departure_time % 60 >= 10\n",
    "                    else \"0\" + str(departure_time % 60)\n",
    "                )\n",
    "            )\n",
    "\n",
    "            if verbose == 1:\n",
    "                # Print detailed timing for current location\n",
    "                print(\n",
    "                    f\"* Location {manager.IndexToNode(index)} (Arrival: {arrival_time_str}, \"\n",
    "                    f\"End of Service Time (Service time: {service_time}) (Skills required: {skills_required}): {end_of_service_time_str}, Break: {break_time_str}, \"\n",
    "                    f\"Departure: {departure_time_str}, Next travel time: {next_travel_time}) -> \"\n",
    "                )\n",
    "\n",
    "            index = next_index\n",
    "\n",
    "        # Handle final location's arrival time\n",
    "        final_arrival_time = solution.Min(time_dimension.CumulVar(index))\n",
    "        end_day = final_arrival_time\n",
    "        final_arrival_time_str = (\n",
    "            str(final_arrival_time // 60)\n",
    "            + \"h\"\n",
    "            + (\n",
    "                str(final_arrival_time % 60)\n",
    "                if final_arrival_time % 60 >= 10\n",
    "                else \"0\" + str(final_arrival_time % 60)\n",
    "            )\n",
    "        )\n",
    "        if verbose == 1:\n",
    "            print(\n",
    "                f\"* Location {manager.IndexToNode(index) + 1} (Arrival: {final_arrival_time_str})\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Number of small breaks (<30min): {nb_break_inf_veh}; Number of big breaks (>30min): {nb_break_sup_veh}\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Total commuting time for vehicle {inter_id}: {vehicle_commuting_time} minutes\"\n",
    "            )\n",
    "\n",
    "        if end_day - start_day > 1:  # Superior than 1 minute\n",
    "            list_length_day.append((start_day, end_day))\n",
    "            avg_length_day += end_day - start_day\n",
    "\n",
    "            start_day_str = (\n",
    "                str(start_day // 60)\n",
    "                + \"h\"\n",
    "                + (\n",
    "                    str(start_day % 60)\n",
    "                    if start_day % 60 >= 10\n",
    "                    else \"0\" + str(start_day % 60)\n",
    "                )\n",
    "            )\n",
    "            end_day_str = (\n",
    "                str(end_day // 60)\n",
    "                + \"h\"\n",
    "                + (str(end_day % 60) if end_day % 60 >= 10 else \"0\" + str(end_day % 60))\n",
    "            )\n",
    "\n",
    "            if verbose == 1:\n",
    "                print(\n",
    "                    f\"Start of the day: {start_day_str}; End of the day: {end_day_str}\"\n",
    "                )\n",
    "        if verbose == 1:\n",
    "            print(\"\\n\")\n",
    "\n",
    "    nb_available_inter = data[\"num_vehicles\"]\n",
    "    print(f\"Total available inter: {nb_available_inter}\")\n",
    "    print(f\"Total inter who worked: {nb_inter_used}\")\n",
    "    print(f\"Toal number of visited nodes: {nb_visits}\")\n",
    "    print(f\"Overall total commuting time: {overall_total_commuting_time} minutes\")\n",
    "    print(f\"Number of cars used: {nb_cars_used}\")\n",
    "    eq_co2_cars = eq_co2_car(overall_total_car_commuting_time)\n",
    "    print(\n",
    "        f\"Overall total commuting time for cars: {overall_total_car_commuting_time} minutes ({eq_co2_cars} kgCO2)\"\n",
    "    )\n",
    "    print(f\"Number of bikes used: {nb_bikes_used}\")\n",
    "    eq_co2_bikes = eq_co2_elec_bike(overall_total_bike_commuting_time)\n",
    "    print(\n",
    "        f\"Overall total commuting time for bikes: {overall_total_bike_commuting_time} minutes ({eq_co2_bikes} kgCO2)\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Total number of small breaks (<30min): {nb_break_inf}; Total number of big breaks (>30min): {nb_break_sup}\"\n",
    "    )\n",
    "\n",
    "    avg_length_day = avg_length_day / nb_inter_used\n",
    "    avg_length_day_str = round(avg_length_day)\n",
    "    avg_length_day_str = (\n",
    "        str(avg_length_day_str // 60)\n",
    "        + \"h\"\n",
    "        + (\n",
    "            str(avg_length_day_str % 60)\n",
    "            if avg_length_day_str % 60 >= 10\n",
    "            else \"0\" + str(avg_length_day_str % 60)\n",
    "        )\n",
    "    )\n",
    "    print(f\"Average length of a day of work: {avg_length_day_str}\")\n",
    "\n",
    "    dict_results = {\n",
    "        \"total_commuting_time\": overall_total_commuting_time,\n",
    "        \"total_car_commuting_time\": overall_total_car_commuting_time,\n",
    "        \"total_bike_commuting_time\": overall_total_bike_commuting_time,\n",
    "        \"nb_available_inter\": nb_available_inter,\n",
    "        \"nb_inter_used\": nb_inter_used,\n",
    "        \"nb_cars_used\": nb_cars_used,\n",
    "        \"nb_bikes_used\": nb_bikes_used,\n",
    "        \"avg_length_day\": avg_length_day,\n",
    "        \"list_length_day\": list_length_day,\n",
    "        \"eq_co2_cars\": eq_co2_cars,\n",
    "        \"eq_co2_bikes\": eq_co2_bikes,\n",
    "        \"nb_break_inf\": nb_break_inf,\n",
    "        \"nb_break_sup\": nb_break_sup,\n",
    "        \"nb_visits\": nb_visits,\n",
    "        \"nb_dropped_nodes\": count_dropped_nodes,\n",
    "    }\n",
    "\n",
    "    return dict_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. Bikes fleet proportion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_is_car(list_available_inter, df_inter):\n",
    "    list_is_car = []\n",
    "    for id_inter in list_available_inter:\n",
    "        condition = df_inter[\"ID Intervenant\"] == id_inter\n",
    "        if df_inter.loc[condition, \"Véhicule personnel\"].values[0] == \"Oui\":\n",
    "            list_is_car.append(1)\n",
    "        else:\n",
    "            list_is_car.append(0)\n",
    "\n",
    "    return list_is_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synth_is_car(df_synth_inter):\n",
    "    list_is_car = []\n",
    "    for car in df_synth_inter[\"Véhicule personnel\"]:\n",
    "        if car == \"Oui\":\n",
    "            list_is_car.append(1)\n",
    "        else:\n",
    "            list_is_car.append(0)\n",
    "\n",
    "    return list_is_car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the 'bike_proportion' parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vehicle_type_list(nb_inter, bike_proportion):\n",
    "    nb_bikes = int(nb_inter * bike_proportion)\n",
    "    vehicle_type_list = [0] * nb_bikes + [1] * (nb_inter - nb_bikes)\n",
    "    random.shuffle(vehicle_type_list)\n",
    "    return vehicle_type_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Inter constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inter_skills(list_available_inter, df_inter):\n",
    "    list_all_inter_skills = []\n",
    "    for id_inter in list_available_inter:\n",
    "        condition = df_inter[\"ID Intervenant\"] == id_inter\n",
    "        tmp_skills = df_inter.loc[condition, \"Compétences\"].values[0]\n",
    "        list_skills = [x.strip() for x in tmp_skills.split(sep=\",\")]\n",
    "        list_all_inter_skills.append(list_skills)\n",
    "\n",
    "    return list_all_inter_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synth_inter_skills(synth_inter_df):\n",
    "    list_all_inter_skills = []\n",
    "    for tmp_skills in synth_inter_df[\"Compétences\"]:\n",
    "        list_skills = [x.strip() for x in tmp_skills.split(sep=\",\")]\n",
    "        list_all_inter_skills.append(list_skills)\n",
    "\n",
    "    return list_all_inter_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Availability constraints\n",
    "def create_real_data_model_with_synth(\n",
    "    df_og_need,\n",
    "    full_time_matrix_car,\n",
    "    full_time_matrix_bike,\n",
    "    list_available_inter,\n",
    "    nb_synth_clients=0,\n",
    "    nb_synth_inter=0,\n",
    "    client_id_to_idx=client_id_to_idx,\n",
    "    inter_id_to_idx=inter_id_to_idx,\n",
    "    nb_full_client=nb_full_client,\n",
    "    list_skills=list_skills,\n",
    "    df_inter=df_inter,\n",
    "    inter_constraints=False,\n",
    "    date=None,\n",
    "    bike_proportion=0.0,\n",
    "    workload_capacity=7,\n",
    "):\n",
    "    nb_needs = len(df_og_need)\n",
    "    nb_inter = len(list_available_inter)\n",
    "    data = {}\n",
    "\n",
    "    # Initialization\n",
    "    data[\"og_time_matrix_car\"] = [\n",
    "        [4000 for i in range(nb_needs + nb_inter)] for k in range(nb_needs + nb_inter)\n",
    "    ]\n",
    "    data[\"og_time_matrix_bike\"] = [\n",
    "        [4000 for i in range(nb_needs + nb_inter)] for k in range(nb_needs + nb_inter)\n",
    "    ]\n",
    "\n",
    "    # Create original time matrix\n",
    "    for i in range(nb_needs):\n",
    "        need_id_client = df_og_need[\"ID Client\"][i]\n",
    "        need_idx_client = client_id_to_idx[need_id_client]\n",
    "\n",
    "        for j in range(nb_needs):\n",
    "            other_id_client = df_og_need[\"ID Client\"][j]\n",
    "            other_idx_client = client_id_to_idx[other_id_client]\n",
    "\n",
    "            travel_time_car = full_time_matrix_car[need_idx_client, other_idx_client]\n",
    "            travel_time_bike = full_time_matrix_bike[need_idx_client, other_idx_client]\n",
    "            data[\"og_time_matrix_car\"][i][j] = travel_time_car\n",
    "            data[\"og_time_matrix_bike\"][i][j] = travel_time_bike\n",
    "\n",
    "        for j in range(nb_inter):\n",
    "            id_inter = list_available_inter[j]\n",
    "            idx_inter = inter_id_to_idx[id_inter]\n",
    "\n",
    "            travel_time_car = full_time_matrix_car[need_idx_client][\n",
    "                nb_full_client + idx_inter\n",
    "            ]\n",
    "            travel_time_bike = full_time_matrix_bike[need_idx_client][\n",
    "                nb_full_client + idx_inter\n",
    "            ]\n",
    "\n",
    "            data[\"og_time_matrix_car\"][i][nb_needs + j] = travel_time_car\n",
    "            data[\"og_time_matrix_car\"][nb_needs + j][i] = data[\"og_time_matrix_car\"][i][\n",
    "                nb_needs + j\n",
    "            ]\n",
    "            data[\"og_time_matrix_bike\"][i][nb_needs + j] = travel_time_bike\n",
    "            data[\"og_time_matrix_bike\"][nb_needs + j][i] = data[\"og_time_matrix_bike\"][\n",
    "                i\n",
    "            ][nb_needs + j]\n",
    "    for i in range(nb_needs + nb_inter):\n",
    "        data[\"og_time_matrix_car\"][i][i] = 0\n",
    "        data[\"og_time_matrix_bike\"][i][i] = 0\n",
    "\n",
    "    # Create new time matrix from orginial adding synthetic travel times\n",
    "    (\n",
    "        data[\"time_matrix_car\"],\n",
    "        data[\"time_matrix_bike\"],\n",
    "        synth_client_needs_df,\n",
    "        synth_available_inter_df,\n",
    "    ) = add_actors(\n",
    "        df_og_need,\n",
    "        df_inter,\n",
    "        list_available_inter,\n",
    "        data[\"og_time_matrix_car\"],\n",
    "        data[\"og_time_matrix_bike\"],\n",
    "        nb_synth_clients,\n",
    "        nb_synth_inter,\n",
    "        client_locations,\n",
    "        inter_locations,\n",
    "        inter_synth_constraints=inter_constraints,\n",
    "        date=date,\n",
    "    )\n",
    "\n",
    "    if inter_constraints:\n",
    "        nb_synth_inter = len(synth_available_inter_df)\n",
    "\n",
    "    data[\"service_times\"] = [\n",
    "        0 for i in range(nb_needs + nb_inter + nb_synth_clients + nb_synth_inter)\n",
    "    ]\n",
    "    data[\"time_windows\"] = [\n",
    "        (0, 1440)\n",
    "        for i in range(nb_needs + nb_inter + nb_synth_clients + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    data[\"num_vehicles\"] = nb_inter + nb_synth_inter\n",
    "\n",
    "    if inter_constraints:\n",
    "        list_is_car = get_is_car(list_available_inter, df_inter)\n",
    "        if nb_synth_inter > 0:\n",
    "            list_is_car = [*list_is_car, *get_synth_is_car(synth_available_inter_df)]\n",
    "        data[\"is_car\"] = list_is_car\n",
    "    else:\n",
    "        data[\"is_car\"] = [1 for i in range(nb_inter + nb_synth_inter)]\n",
    "    data[\"starts\"] = [\n",
    "        nb_needs + nb_synth_clients + i for i in range(nb_inter + nb_synth_inter)\n",
    "    ]\n",
    "    data[\"ends\"] = [\n",
    "        nb_needs + nb_synth_clients + i for i in range(nb_inter + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    if inter_constraints:\n",
    "        list_inter_skills = get_inter_skills(list_available_inter, df_inter)\n",
    "        if nb_synth_inter > 0:\n",
    "            list_inter_skills = [\n",
    "                *list_inter_skills,\n",
    "                *get_synth_inter_skills(synth_available_inter_df),\n",
    "            ]\n",
    "        data[\"vehicle_skills\"] = list_inter_skills\n",
    "    else:\n",
    "        data[\"vehicle_skills\"] = [list_skills for i in range(nb_inter + nb_synth_inter)]\n",
    "    data[\"node_requirements\"] = [\n",
    "        None for i in range(nb_needs + nb_inter + nb_synth_clients + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    for i in range(nb_needs + nb_synth_clients):\n",
    "        if i < nb_needs:\n",
    "            service_time = int(df_og_need[\"Durée\"][i])\n",
    "            data[\"service_times\"][i] = service_time\n",
    "\n",
    "            time_window_temp = (\n",
    "                df_og_need[\"tranche_horaire\"][i]\n",
    "                .replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .split()\n",
    "            )\n",
    "            time_window_start = int(float(time_window_temp[0]) * 60)\n",
    "            time_window_end = int(float(time_window_temp[1]) * 60)\n",
    "            data[\"time_windows\"][i] = (time_window_start, time_window_end)\n",
    "\n",
    "            skills_required = df_og_need[\"Prestation\"][i]\n",
    "            data[\"node_requirements\"][i] = skills_required\n",
    "        else:\n",
    "            service_time = int(synth_client_needs_df[\"Durée\"][i - nb_needs])\n",
    "            data[\"service_times\"][i] = service_time\n",
    "\n",
    "            time_window_temp = (\n",
    "                synth_client_needs_df[\"tranche_horaire\"][i - nb_needs]\n",
    "                .replace(\"[\", \"\")\n",
    "                .replace(\"]\", \"\")\n",
    "                .replace(\",\", \"\")\n",
    "                .split()\n",
    "            )\n",
    "            time_window_start = int(float(time_window_temp[0]) * 60)\n",
    "            time_window_end = int(float(time_window_temp[1]) * 60)\n",
    "            data[\"time_windows\"][i] = (time_window_start, time_window_end)\n",
    "\n",
    "            skills_required = synth_client_needs_df[\"Prestation\"][i - nb_needs]\n",
    "            data[\"node_requirements\"][i] = skills_required\n",
    "\n",
    "    data[\"time_windows_with_service\"] = [\n",
    "        (\n",
    "            data[\"time_windows\"][i][0] + data[\"service_times\"][i],\n",
    "            data[\"time_windows\"][i][1] + data[\"service_times\"][i],\n",
    "        )\n",
    "        for i in range(len(data[\"service_times\"]))\n",
    "    ]\n",
    "\n",
    "    data[\"workload_per_node\"] = [\n",
    "        *[1 for i in range(nb_needs + nb_synth_clients)],\n",
    "        *[0 for k in range(nb_inter + nb_synth_inter)],\n",
    "    ]  # Useless for now but could be used to differ workload from each node\n",
    "    data[\"workload_capacity\"] = [\n",
    "        workload_capacity for i in range(nb_inter + nb_synth_inter)\n",
    "    ]\n",
    "\n",
    "    if bike_proportion > 0.00001:\n",
    "        data[\"is_car\"] = generate_vehicle_type_list(\n",
    "            nb_synth_inter + nb_inter, bike_proportion\n",
    "        )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.7. Training policies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add training for inter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Mandatory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Running scenarios\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dates = [\n",
    "    \"2024-01-15\",\n",
    "    \"2024-01-16\",\n",
    "    \"2024-01-17\",\n",
    "    \"2024-01-18\",\n",
    "    \"2024-01-19\",\n",
    "    \"2024-01-20\",\n",
    "    \"2024-01-21\",\n",
    "]\n",
    "list_skills = c_l_need[\"Prestation\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_real_data_with_synth(\n",
    "    df_need,\n",
    "    full_time_matrix_car,\n",
    "    full_time_matrix_bike,\n",
    "    list_available_inter,\n",
    "    nb_synth_clients=0,\n",
    "    nb_synth_inter=0,\n",
    "    workload_capacity=7,\n",
    "    bike_proportion=0,\n",
    "    verbose=0,\n",
    "    inter_constraints=False,\n",
    "    date=None,\n",
    "):\n",
    "    \"\"\"Solve the VRP with time windows from specified locations.\"\"\"\n",
    "    # Instantiate the data problem.\n",
    "    data = create_real_data_model_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        list_available_inter,\n",
    "        nb_synth_clients=nb_synth_clients,\n",
    "        nb_synth_inter=nb_synth_inter,\n",
    "        bike_proportion=bike_proportion,\n",
    "        workload_capacity=workload_capacity\n",
    "        + 1,  # To count the initial double travel (from home / to home)\n",
    "        inter_constraints=inter_constraints,\n",
    "        date=date,\n",
    "    )\n",
    "\n",
    "    # Create the routing index manager.\n",
    "    manager = pywrapcp.RoutingIndexManager(\n",
    "        len(data[\"time_matrix_car\"]), data[\"num_vehicles\"], data[\"starts\"], data[\"ends\"]\n",
    "    )\n",
    "\n",
    "    # Create Routing Model.\n",
    "    routing = pywrapcp.RoutingModel(manager)\n",
    "\n",
    "    # Create and register a transit callback.\n",
    "    def time_callback(from_index, to_index, type):\n",
    "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
    "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
    "        from_node = manager.IndexToNode(from_index)\n",
    "        to_node = manager.IndexToNode(to_index)\n",
    "        service_time = data[\"service_times\"][to_node]\n",
    "        if type == 1:  # Car\n",
    "            return data[\"time_matrix_car\"][from_node][to_node] + service_time\n",
    "            # return data[\"time_matrix_car\"][from_node][to_node]\n",
    "        else:\n",
    "            return data[\"time_matrix_bike\"][from_node][to_node] + service_time\n",
    "            # return data[\"time_matrix_bike\"][from_node][to_node]\n",
    "\n",
    "    car_callback = partial(time_callback, type=1)\n",
    "    bike_callback = partial(time_callback, type=0)\n",
    "\n",
    "    car_index = routing.RegisterTransitCallback(car_callback)\n",
    "    bike_index = routing.RegisterTransitCallback(bike_callback)\n",
    "\n",
    "    list_index = []\n",
    "    for k in range(data[\"num_vehicles\"]):\n",
    "        if data[\"is_car\"][k] == 1:\n",
    "            routing.SetArcCostEvaluatorOfVehicle(car_index, k)\n",
    "            list_index.append(car_index)\n",
    "        else:\n",
    "            routing.SetArcCostEvaluatorOfVehicle(bike_index, k)\n",
    "            list_index.append(bike_index)\n",
    "\n",
    "    # Enforce node requirements based on vehicle skills\n",
    "    for node_idx, requirement in enumerate(data[\"node_requirements\"]):\n",
    "        if requirement:  # Check if the node has specific skill requirements\n",
    "            allowed_vehicles = [\n",
    "                vehicle_id\n",
    "                for vehicle_id, skills in enumerate(data[\"vehicle_skills\"])\n",
    "                if requirement in skills\n",
    "            ]\n",
    "            manager_idx = manager.NodeToIndex(node_idx)\n",
    "            if manager_idx >= 0:  # Ensure manager index is valid\n",
    "                routing.SetAllowedVehiclesForIndex(allowed_vehicles, manager_idx)\n",
    "\n",
    "    # Add Time constraint.\n",
    "    dimension_name = \"Time\"\n",
    "    routing.AddDimensionWithVehicleTransitAndCapacity(\n",
    "        list_index,\n",
    "        10000,  # no slack\n",
    "        [10000 for i in range(data[\"num_vehicles\"])],  # vehicle maximum travel time\n",
    "        True,  # start cumul to zero\n",
    "        dimension_name,\n",
    "    )\n",
    "\n",
    "    time_dimension = routing.GetDimensionOrDie(dimension_name)\n",
    "\n",
    "    def workload_callback(from_index):\n",
    "        return 1\n",
    "\n",
    "    workload_index = routing.RegisterUnaryTransitCallback(workload_callback)\n",
    "    routing.AddDimensionWithVehicleCapacity(\n",
    "        workload_index,\n",
    "        slack_max=0,  # No slack\n",
    "        vehicle_capacities=data[\"workload_capacity\"],  # Maximum \"load\" per vehicle\n",
    "        fix_start_cumul_to_zero=True,\n",
    "        name=\"LoadBalance\",\n",
    "    )\n",
    "\n",
    "    # Allow to drop nodes.\n",
    "    penalty = 10000\n",
    "    nb_needs = len(df_need) + nb_synth_clients\n",
    "    for node in range(nb_needs):\n",
    "        routing.AddDisjunction([manager.NodeToIndex(node)], penalty)\n",
    "\n",
    "    # Add time window constraints for each location except start and end.\n",
    "    for location_idx, time_window in enumerate(data[\"time_windows_with_service\"]):\n",
    "        if location_idx in data[\"starts\"]:\n",
    "            continue\n",
    "        if location_idx in data[\"ends\"]:\n",
    "            continue\n",
    "        index = manager.NodeToIndex(location_idx)\n",
    "        start_time_window = time_window[0]\n",
    "        end_time_window = time_window[1]\n",
    "        time_dimension.CumulVar(index).SetRange(start_time_window, end_time_window)\n",
    "\n",
    "    # Instantiate route start and end times to produce feasible times.\n",
    "    for i in range(data[\"num_vehicles\"]):\n",
    "        routing.AddVariableMinimizedByFinalizer(\n",
    "            time_dimension.CumulVar(routing.Start(i))\n",
    "        )\n",
    "        routing.AddVariableMinimizedByFinalizer(time_dimension.CumulVar(routing.End(i)))\n",
    "\n",
    "    # Setting first solution heuristic.\n",
    "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
    "    # search_parameters.log_search = True\n",
    "    search_parameters.first_solution_strategy = (\n",
    "        routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC\n",
    "    )\n",
    "    search_parameters.local_search_metaheuristic = (\n",
    "        routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH\n",
    "    )\n",
    "    search_parameters.time_limit.FromSeconds(1)\n",
    "\n",
    "    # Solve the problem.\n",
    "    solution = routing.SolveWithParameters(search_parameters)\n",
    "\n",
    "    # Print solution on console.\n",
    "    if solution:\n",
    "        # print_solution(data, manager, routing, solution)\n",
    "        dict_result = print_detailed_solution_real_data(\n",
    "            data, manager, routing, solution, list_available_inter, verbose=verbose\n",
    "        )\n",
    "        dict_result[\"data\"] = data\n",
    "        return dict_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.A. Pas de contraintes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 297 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 297 minutes (28.214999999999996 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h26\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 20\n",
      "Toal number of visited nodes: 111\n",
      "Overall total commuting time: 385 minutes\n",
      "Number of cars used: 20\n",
      "Overall total commuting time for cars: 385 minutes (36.575 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 31\n",
      "Average length of a day of work: 10h51\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 282 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 282 minutes (26.79 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 47; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 9h51\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 331 minutes\n",
      "Number of cars used: 17\n",
      "Overall total commuting time for cars: 331 minutes (31.445 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 11h20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 20\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 312 minutes\n",
      "Number of cars used: 20\n",
      "Overall total commuting time for cars: 312 minutes (29.639999999999997 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 52; Total number of big breaks (>30min): 27\n",
      "Average length of a day of work: 10h07\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 69\n",
      "Overall total commuting time: 219 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 219 minutes (20.805 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 31; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h04\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 14\n",
      "Toal number of visited nodes: 65\n",
      "Overall total commuting time: 179 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 179 minutes (17.005 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 29; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h15\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_1_a = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need, full_time_matrix_car, full_time_matrix_bike, full_inter_list, verbose=0\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_1_a.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.B. Avec contraintes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: 67; (Total: 1)\n",
      "Total available inter: 17\n",
      "Total inter who worked: 16\n",
      "Toal number of visited nodes: 102\n",
      "Overall total commuting time: 575 minutes\n",
      "Number of cars used: 13\n",
      "Overall total commuting time for cars: 410 minutes (38.95 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 165 minutes (0.11000000000000001 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h51\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: 17; 88; (Total: 2)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 109\n",
      "Overall total commuting time: 721 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 631 minutes (59.94499999999999 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 90 minutes (0.06 kgCO2)\n",
      "Total number of small breaks (<30min): 73; Total number of big breaks (>30min): 18\n",
      "Average length of a day of work: 9h54\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 14\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 586 minutes\n",
      "Number of cars used: 11\n",
      "Overall total commuting time for cars: 473 minutes (44.934999999999995 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 113 minutes (0.07533333333333334 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 17\n",
      "Average length of a day of work: 10h20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 489 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 428 minutes (40.66 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 61 minutes (0.04066666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 59; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 10h48\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 650 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 617 minutes (58.614999999999995 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 33 minutes (0.022 kgCO2)\n",
      "Total number of small breaks (<30min): 65; Total number of big breaks (>30min): 19\n",
      "Average length of a day of work: 11h09\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: 1; 2; 10; 11; 12; 18; 19; 25; 29; 40; 43; 44; 58; (Total: 13)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 336 minutes\n",
      "Number of cars used: 7\n",
      "Overall total commuting time for cars: 283 minutes (26.884999999999998 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 53 minutes (0.035333333333333335 kgCO2)\n",
      "Total number of small breaks (<30min): 37; Total number of big breaks (>30min): 11\n",
      "Average length of a day of work: 10h36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: 1; 5; 11; 12; 13; 32; 38; 40; 42; (Total: 9)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 278 minutes\n",
      "Number of cars used: 7\n",
      "Overall total commuting time for cars: 236 minutes (22.419999999999998 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 42 minutes (0.027999999999999997 kgCO2)\n",
      "Total number of small breaks (<30min): 34; Total number of big breaks (>30min): 14\n",
      "Average length of a day of work: 11h28\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_1_b = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "    list_available_inter = get_list_og_available(date, df_inter)\n",
    "\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        list_available_inter,\n",
    "        inter_constraints=True,\n",
    "        workload_capacity=7,\n",
    "        verbose=0,\n",
    "        date=date,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_1_b.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Proportions de vélo (tous les intervenants disponibles, tous les skills, pas de clients en plus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.A. Proportion: 0%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 281 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 281 minutes (26.695 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h40\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 20\n",
      "Toal number of visited nodes: 111\n",
      "Overall total commuting time: 380 minutes\n",
      "Number of cars used: 20\n",
      "Overall total commuting time for cars: 380 minutes (36.1 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 61; Total number of big breaks (>30min): 30\n",
      "Average length of a day of work: 10h58\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 274 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 274 minutes (26.03 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 47; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 10h01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 331 minutes\n",
      "Number of cars used: 17\n",
      "Overall total commuting time for cars: 331 minutes (31.445 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 11h20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 19\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 325 minutes\n",
      "Number of cars used: 19\n",
      "Overall total commuting time for cars: 325 minutes (30.875 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 53; Total number of big breaks (>30min): 27\n",
      "Average length of a day of work: 10h32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 69\n",
      "Overall total commuting time: 219 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 219 minutes (20.805 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 31; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h04\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 14\n",
      "Toal number of visited nodes: 65\n",
      "Overall total commuting time: 179 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 179 minutes (17.005 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 29; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h15\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_a = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "\n",
    "    # Reminder: inter_constraints = False sets the reference to 'no constraints' and bike_proportion builds on top\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        full_inter_list,\n",
    "        inter_constraints=False,\n",
    "        bike_proportion=0.0,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_a.append(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: 67; (Total: 1)\n",
      "Total available inter: 17\n",
      "Total inter who worked: 16\n",
      "Toal number of visited nodes: 102\n",
      "Overall total commuting time: 568 minutes\n",
      "Number of cars used: 13\n",
      "Overall total commuting time for cars: 403 minutes (38.285 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 165 minutes (0.11000000000000001 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h50\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: 17; (Total: 1)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 110\n",
      "Overall total commuting time: 615 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 530 minutes (50.35 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 85 minutes (0.056666666666666664 kgCO2)\n",
      "Total number of small breaks (<30min): 70; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h25\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 14\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 584 minutes\n",
      "Number of cars used: 11\n",
      "Overall total commuting time for cars: 471 minutes (44.745 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 113 minutes (0.07533333333333334 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 17\n",
      "Average length of a day of work: 10h31\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 478 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 417 minutes (39.614999999999995 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 61 minutes (0.04066666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 59; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 10h51\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 650 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 617 minutes (58.614999999999995 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 33 minutes (0.022 kgCO2)\n",
      "Total number of small breaks (<30min): 65; Total number of big breaks (>30min): 19\n",
      "Average length of a day of work: 11h09\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: 1; 2; 10; 11; 12; 18; 19; 25; 29; 40; 43; 44; 58; (Total: 13)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 336 minutes\n",
      "Number of cars used: 7\n",
      "Overall total commuting time for cars: 283 minutes (26.884999999999998 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 53 minutes (0.035333333333333335 kgCO2)\n",
      "Total number of small breaks (<30min): 37; Total number of big breaks (>30min): 11\n",
      "Average length of a day of work: 10h36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: 1; 5; 11; 12; 13; 32; 38; 40; 42; (Total: 9)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 278 minutes\n",
      "Number of cars used: 7\n",
      "Overall total commuting time for cars: 236 minutes (22.419999999999998 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 42 minutes (0.027999999999999997 kgCO2)\n",
      "Total number of small breaks (<30min): 34; Total number of big breaks (>30min): 14\n",
      "Average length of a day of work: 11h28\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_a_bis = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "    list_available_inter = get_list_og_available(date, df_inter)\n",
    "\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        list_available_inter,\n",
    "        inter_constraints=True,\n",
    "        workload_capacity=7,\n",
    "        verbose=0,\n",
    "        date=date,\n",
    "        bike_proportion=0.0,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_a_bis.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.B. Proportion: 10%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 330 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 330 minutes (31.35 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 59; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 10h59\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 19\n",
      "Toal number of visited nodes: 111\n",
      "Overall total commuting time: 430 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 424 minutes (40.279999999999994 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 6 minutes (0.003999999999999999 kgCO2)\n",
      "Total number of small breaks (<30min): 62; Total number of big breaks (>30min): 30\n",
      "Average length of a day of work: 11h06\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 287 minutes\n",
      "Number of cars used: 17\n",
      "Overall total commuting time for cars: 251 minutes (23.845 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 36 minutes (0.024 kgCO2)\n",
      "Total number of small breaks (<30min): 46; Total number of big breaks (>30min): 27\n",
      "Average length of a day of work: 10h23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 19\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 323 minutes\n",
      "Number of cars used: 17\n",
      "Overall total commuting time for cars: 298 minutes (28.309999999999995 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 25 minutes (0.016666666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 24\n",
      "Average length of a day of work: 9h55\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 346 minutes\n",
      "Number of cars used: 16\n",
      "Overall total commuting time for cars: 330 minutes (31.35 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 16 minutes (0.010666666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 55; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 9h33\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 69\n",
      "Overall total commuting time: 214 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 214 minutes (20.33 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 30; Total number of big breaks (>30min): 24\n",
      "Average length of a day of work: 10h20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 13\n",
      "Toal number of visited nodes: 65\n",
      "Overall total commuting time: 177 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 175 minutes (16.625 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 2 minutes (0.0013333333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 29; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h33\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_b = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "\n",
    "    # Reminder: inter_constraints = False sets the reference to 'no constraints' and bike_proportion builds on top\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        full_inter_list,\n",
    "        inter_constraints=False,\n",
    "        bike_proportion=0.1,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_b.append(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 17\n",
      "Total inter who worked: 16\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 496 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 484 minutes (45.98 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 12 minutes (0.007999999999999998 kgCO2)\n",
      "Total number of small breaks (<30min): 68; Total number of big breaks (>30min): 19\n",
      "Average length of a day of work: 10h47\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 111\n",
      "Overall total commuting time: 652 minutes\n",
      "Number of cars used: 17\n",
      "Overall total commuting time for cars: 652 minutes (61.94 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 72; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h46\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 14\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 467 minutes\n",
      "Number of cars used: 13\n",
      "Overall total commuting time for cars: 459 minutes (43.605 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 8 minutes (0.005333333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 58; Total number of big breaks (>30min): 19\n",
      "Average length of a day of work: 10h58\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 480 minutes\n",
      "Number of cars used: 16\n",
      "Overall total commuting time for cars: 478 minutes (45.41 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 2 minutes (0.0013333333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 11h11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: 18; (Total: 1)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 98\n",
      "Overall total commuting time: 614 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 568 minutes (53.96 kgCO2)\n",
      "Number of bikes used: 1\n",
      "Overall total commuting time for bikes: 46 minutes (0.030666666666666665 kgCO2)\n",
      "Total number of small breaks (<30min): 66; Total number of big breaks (>30min): 17\n",
      "Average length of a day of work: 10h30\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: 1; 2; 3; 10; 11; 12; 18; 19; 29; 37; 40; 44; 61; (Total: 13)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 332 minutes\n",
      "Number of cars used: 8\n",
      "Overall total commuting time for cars: 332 minutes (31.54 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 37; Total number of big breaks (>30min): 11\n",
      "Average length of a day of work: 10h08\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: 1; 5; 11; 12; 13; 32; 38; 40; 42; (Total: 9)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 301 minutes\n",
      "Number of cars used: 8\n",
      "Overall total commuting time for cars: 301 minutes (28.595 kgCO2)\n",
      "Number of bikes used: 0\n",
      "Overall total commuting time for bikes: 0 minutes (0.0 kgCO2)\n",
      "Total number of small breaks (<30min): 33; Total number of big breaks (>30min): 15\n",
      "Average length of a day of work: 11h42\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_b_bis = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "    list_available_inter = get_list_og_available(date, df_inter)\n",
    "\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        list_available_inter,\n",
    "        inter_constraints=True,\n",
    "        workload_capacity=7,\n",
    "        verbose=0,\n",
    "        date=date,\n",
    "        bike_proportion=0.1,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_b_bis.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.C. Proportion: 25%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 20\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 323 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 309 minutes (29.355 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 14 minutes (0.009333333333333334 kgCO2)\n",
      "Total number of small breaks (<30min): 54; Total number of big breaks (>30min): 29\n",
      "Average length of a day of work: 10h24\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 20\n",
      "Toal number of visited nodes: 111\n",
      "Overall total commuting time: 407 minutes\n",
      "Number of cars used: 18\n",
      "Overall total commuting time for cars: 385 minutes (36.575 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 22 minutes (0.014666666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 64; Total number of big breaks (>30min): 27\n",
      "Average length of a day of work: 11h00\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 261 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 243 minutes (23.085 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 18 minutes (0.012 kgCO2)\n",
      "Total number of small breaks (<30min): 51; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 21\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 387 minutes\n",
      "Number of cars used: 16\n",
      "Overall total commuting time for cars: 336 minutes (31.919999999999998 kgCO2)\n",
      "Number of bikes used: 5\n",
      "Overall total commuting time for bikes: 51 minutes (0.033999999999999996 kgCO2)\n",
      "Total number of small breaks (<30min): 52; Total number of big breaks (>30min): 30\n",
      "Average length of a day of work: 10h12\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 19\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 365 minutes\n",
      "Number of cars used: 15\n",
      "Overall total commuting time for cars: 327 minutes (31.064999999999998 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 38 minutes (0.02533333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 54; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 9h46\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 16\n",
      "Toal number of visited nodes: 69\n",
      "Overall total commuting time: 220 minutes\n",
      "Number of cars used: 13\n",
      "Overall total commuting time for cars: 197 minutes (18.714999999999996 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 23 minutes (0.015333333333333332 kgCO2)\n",
      "Total number of small breaks (<30min): 31; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 9h43\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 13\n",
      "Toal number of visited nodes: 65\n",
      "Overall total commuting time: 171 minutes\n",
      "Number of cars used: 11\n",
      "Overall total commuting time for cars: 167 minutes (15.865 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 4 minutes (0.0026666666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 29; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h56\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_c = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "\n",
    "    # Reminder: inter_constraints = False sets the reference to 'no constraints' and bike_proportion builds on top\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        full_inter_list,\n",
    "        inter_constraints=False,\n",
    "        bike_proportion=0.25,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_c.append(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 17\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 611 minutes\n",
      "Number of cars used: 13\n",
      "Overall total commuting time for cars: 456 minutes (43.32 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 155 minutes (0.10333333333333332 kgCO2)\n",
      "Total number of small breaks (<30min): 64; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h20\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: 17; 74; 88; (Total: 3)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 108\n",
      "Overall total commuting time: 685 minutes\n",
      "Number of cars used: 14\n",
      "Overall total commuting time for cars: 550 minutes (52.25 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 135 minutes (0.09 kgCO2)\n",
      "Total number of small breaks (<30min): 68; Total number of big breaks (>30min): 22\n",
      "Average length of a day of work: 10h38\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 444 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 401 minutes (38.095 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 43 minutes (0.028666666666666663 kgCO2)\n",
      "Total number of small breaks (<30min): 55; Total number of big breaks (>30min): 21\n",
      "Average length of a day of work: 10h28\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 508 minutes\n",
      "Number of cars used: 13\n",
      "Overall total commuting time for cars: 426 minutes (40.47 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 82 minutes (0.05466666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 65; Total number of big breaks (>30min): 21\n",
      "Average length of a day of work: 10h01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: 18; (Total: 1)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 98\n",
      "Overall total commuting time: 680 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 482 minutes (45.79 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 198 minutes (0.13199999999999998 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h59\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: 1; 2; 10; 11; 12; 18; 19; 23; 25; 37; 40; 44; 61; (Total: 13)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 501 minutes\n",
      "Number of cars used: 6\n",
      "Overall total commuting time for cars: 276 minutes (26.22 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 225 minutes (0.15 kgCO2)\n",
      "Total number of small breaks (<30min): 37; Total number of big breaks (>30min): 11\n",
      "Average length of a day of work: 10h02\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: 11; 12; 13; 32; 38; 40; 42; 54; 57; (Total: 9)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 384 minutes\n",
      "Number of cars used: 6\n",
      "Overall total commuting time for cars: 266 minutes (25.27 kgCO2)\n",
      "Number of bikes used: 2\n",
      "Overall total commuting time for bikes: 118 minutes (0.07866666666666666 kgCO2)\n",
      "Total number of small breaks (<30min): 34; Total number of big breaks (>30min): 14\n",
      "Average length of a day of work: 11h32\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_c_bis = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "    list_available_inter = get_list_og_available(date, df_inter)\n",
    "\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        list_available_inter,\n",
    "        inter_constraints=True,\n",
    "        workload_capacity=7,\n",
    "        verbose=0,\n",
    "        date=date,\n",
    "        bike_proportion=0.25,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_c_bis.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2.D. Proportion: 50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 355 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 269 minutes (25.555 kgCO2)\n",
      "Number of bikes used: 6\n",
      "Overall total commuting time for bikes: 86 minutes (0.057333333333333326 kgCO2)\n",
      "Total number of small breaks (<30min): 64; Total number of big breaks (>30min): 21\n",
      "Average length of a day of work: 9h59\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 20\n",
      "Toal number of visited nodes: 111\n",
      "Overall total commuting time: 528 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 415 minutes (39.425 kgCO2)\n",
      "Number of bikes used: 8\n",
      "Overall total commuting time for bikes: 113 minutes (0.07533333333333334 kgCO2)\n",
      "Total number of small breaks (<30min): 68; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 9h51\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 18\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 303 minutes\n",
      "Number of cars used: 10\n",
      "Overall total commuting time for cars: 205 minutes (19.475 kgCO2)\n",
      "Number of bikes used: 8\n",
      "Overall total commuting time for bikes: 98 minutes (0.06533333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 46; Total number of big breaks (>30min): 27\n",
      "Average length of a day of work: 10h08\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 19\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 342 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 253 minutes (24.035 kgCO2)\n",
      "Number of bikes used: 7\n",
      "Overall total commuting time for bikes: 89 minutes (0.05933333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 58; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 10h29\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 99\n",
      "Overall total commuting time: 399 minutes\n",
      "Number of cars used: 12\n",
      "Overall total commuting time for cars: 347 minutes (32.964999999999996 kgCO2)\n",
      "Number of bikes used: 5\n",
      "Overall total commuting time for bikes: 52 minutes (0.034666666666666665 kgCO2)\n",
      "Total number of small breaks (<30min): 56; Total number of big breaks (>30min): 26\n",
      "Average length of a day of work: 11h11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 13\n",
      "Toal number of visited nodes: 69\n",
      "Overall total commuting time: 238 minutes\n",
      "Number of cars used: 10\n",
      "Overall total commuting time for cars: 220 minutes (20.9 kgCO2)\n",
      "Number of bikes used: 3\n",
      "Overall total commuting time for bikes: 18 minutes (0.012 kgCO2)\n",
      "Total number of small breaks (<30min): 35; Total number of big breaks (>30min): 21\n",
      "Average length of a day of work: 10h36\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 24\n",
      "Total inter who worked: 13\n",
      "Toal number of visited nodes: 65\n",
      "Overall total commuting time: 202 minutes\n",
      "Number of cars used: 8\n",
      "Overall total commuting time for cars: 154 minutes (14.629999999999999 kgCO2)\n",
      "Number of bikes used: 5\n",
      "Overall total commuting time for bikes: 48 minutes (0.031999999999999994 kgCO2)\n",
      "Total number of small breaks (<30min): 31; Total number of big breaks (>30min): 21\n",
      "Average length of a day of work: 10h34\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_d = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "\n",
    "    # Reminder: inter_constraints = False sets the reference to 'no constraints' and bike_proportion builds on top\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        full_inter_list,\n",
    "        inter_constraints=False,\n",
    "        bike_proportion=0.5,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_d.append(dict_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2024-01-15\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 17\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 652 minutes\n",
      "Number of cars used: 9\n",
      "Overall total commuting time for cars: 281 minutes (26.695 kgCO2)\n",
      "Number of bikes used: 8\n",
      "Overall total commuting time for bikes: 371 minutes (0.24733333333333332 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 23\n",
      "Average length of a day of work: 10h43\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-16\n",
      "Dropped nodes: 17; 88; (Total: 2)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 17\n",
      "Toal number of visited nodes: 109\n",
      "Overall total commuting time: 687 minutes\n",
      "Number of cars used: 9\n",
      "Overall total commuting time for cars: 381 minutes (36.195 kgCO2)\n",
      "Number of bikes used: 8\n",
      "Overall total commuting time for bikes: 306 minutes (0.20400000000000001 kgCO2)\n",
      "Total number of small breaks (<30min): 68; Total number of big breaks (>30min): 24\n",
      "Average length of a day of work: 11h05\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-17\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 14\n",
      "Toal number of visited nodes: 91\n",
      "Overall total commuting time: 563 minutes\n",
      "Number of cars used: 8\n",
      "Overall total commuting time for cars: 367 minutes (34.864999999999995 kgCO2)\n",
      "Number of bikes used: 6\n",
      "Overall total commuting time for bikes: 196 minutes (0.13066666666666665 kgCO2)\n",
      "Total number of small breaks (<30min): 60; Total number of big breaks (>30min): 17\n",
      "Average length of a day of work: 11h01\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-18\n",
      "Dropped nodes: (Total: 0)\n",
      "Total available inter: 18\n",
      "Total inter who worked: 16\n",
      "Toal number of visited nodes: 103\n",
      "Overall total commuting time: 522 minutes\n",
      "Number of cars used: 9\n",
      "Overall total commuting time for cars: 373 minutes (35.434999999999995 kgCO2)\n",
      "Number of bikes used: 7\n",
      "Overall total commuting time for bikes: 149 minutes (0.09933333333333333 kgCO2)\n",
      "Total number of small breaks (<30min): 63; Total number of big breaks (>30min): 24\n",
      "Average length of a day of work: 11h13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-19\n",
      "Dropped nodes: 18; 40; (Total: 2)\n",
      "Total available inter: 15\n",
      "Total inter who worked: 15\n",
      "Toal number of visited nodes: 97\n",
      "Overall total commuting time: 940 minutes\n",
      "Number of cars used: 8\n",
      "Overall total commuting time for cars: 390 minutes (37.05 kgCO2)\n",
      "Number of bikes used: 7\n",
      "Overall total commuting time for bikes: 550 minutes (0.36666666666666664 kgCO2)\n",
      "Total number of small breaks (<30min): 65; Total number of big breaks (>30min): 17\n",
      "Average length of a day of work: 10h23\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-20\n",
      "Dropped nodes: 1; 2; 10; 11; 12; 18; 19; 30; 37; 40; 43; 44; 58; (Total: 13)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 418 minutes\n",
      "Number of cars used: 4\n",
      "Overall total commuting time for cars: 154 minutes (14.629999999999999 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 264 minutes (0.176 kgCO2)\n",
      "Total number of small breaks (<30min): 37; Total number of big breaks (>30min): 11\n",
      "Average length of a day of work: 10h46\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Date: 2024-01-21\n",
      "Dropped nodes: 1; 3; 5; 11; 12; 13; 38; 40; 42; (Total: 9)\n",
      "Total available inter: 8\n",
      "Total inter who worked: 8\n",
      "Toal number of visited nodes: 56\n",
      "Overall total commuting time: 421 minutes\n",
      "Number of cars used: 4\n",
      "Overall total commuting time for cars: 186 minutes (17.669999999999998 kgCO2)\n",
      "Number of bikes used: 4\n",
      "Overall total commuting time for bikes: 235 minutes (0.15666666666666668 kgCO2)\n",
      "Total number of small breaks (<30min): 37; Total number of big breaks (>30min): 11\n",
      "Average length of a day of work: 10h53\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_scenario_7_2_d_bis = []\n",
    "\n",
    "for date in list_dates:\n",
    "    condition = c_l_need[\"Date\"] == date\n",
    "    df_need = c_l_need[condition].copy()\n",
    "    df_need.drop(columns=[\"Date\"], inplace=True)\n",
    "    df_need.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    print(f\"Date: {date}\")\n",
    "    list_available_inter = get_list_og_available(date, df_inter)\n",
    "\n",
    "    dict_results = main_real_data_with_synth(\n",
    "        df_need,\n",
    "        full_time_matrix_car,\n",
    "        full_time_matrix_bike,\n",
    "        list_available_inter,\n",
    "        inter_constraints=True,\n",
    "        workload_capacity=7,\n",
    "        verbose=0,\n",
    "        date=date,\n",
    "        bike_proportion=0.5,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "    list_scenario_7_2_d_bis.append(dict_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3. Ajout de compétences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
